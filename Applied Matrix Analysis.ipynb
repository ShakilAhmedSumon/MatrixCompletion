{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c709106f",
   "metadata": {},
   "source": [
    "====================================================================================\n",
    "# Project Name: Matrix Completion with Deep Learning\n",
    "## Class Name: Applied Matrix Analysis\n",
    "## Student Name: Shakil Ahmed Sumon\n",
    "===================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475e1318",
   "metadata": {},
   "source": [
    "# Deep Meural Networks (DNN) model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110882bf",
   "metadata": {},
   "source": [
    "## Importing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94f998f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn, optim\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c07899b",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf1dd0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root = './data', train = True, download = True)\n",
    "test_data = datasets.MNIST(root = './data', train = False, download = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7682d2a2",
   "metadata": {},
   "source": [
    "## Creating a dataset class for loading the data into the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1827dd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedMNISTDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.mask = mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image, _ = self.data[idx]\n",
    "        image = np.array(image)\n",
    "        image = torch.from_numpy(image).float()\n",
    "\n",
    "        return image, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b2d2e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MaskedMNISTDataset\n",
    "train_dataset = MaskedMNISTDataset(train_data)\n",
    "test_dataset = MaskedMNISTDataset(test_data)\n",
    "\n",
    "# Split the train dataset into training and validation\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a0022ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(28*28, 28*2)\n",
    "        self.linear_2 = nn.Linear(28*2, 14*2)\n",
    "        self.linear_3 = nn.Linear(14*2, 28*28)\n",
    "        self.linear_4 = nn.Linear(28*28, 28*28)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        output = self.linear_1(x)\n",
    "        output = self.linear_2(self.relu(output))\n",
    "        output = self.linear_3(self.relu(output))\n",
    "        output = self.linear_4(self.relu(output))\n",
    "        return torch.tanh(output)\n",
    "\n",
    "# Instantiate the model, loss function and optimizer\n",
    "model = LinearModel()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Parralleize model in case of multiple GPUs\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "loss_array = []\n",
    "# Training Loop\n",
    "def train_model(model, criterion, optimizer, num_epochs=500):\n",
    "  \n",
    "  best_loss = 10000\n",
    "  for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "      \n",
    "      inputs = inputs.view(inputs.size(0), -1).to(device)/255.0\n",
    "      mask = torch.rand(inputs.size()) > 0.5\n",
    "      inputs = inputs * mask.to(device)\n",
    "      labels = labels.view(labels.size(0), -1).to(device)/255.0\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs[mask], labels[mask])\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item()\n",
    "\n",
    "    \n",
    "    val_loss = validate_model(model, val_loader, criterion)\n",
    "    loss_array.append(val_loss)\n",
    "    \n",
    "    # saving the the model for best loss\n",
    "    if val_loss < best_loss:\n",
    "      best_loss = val_loss\n",
    "      last_checkpoint_info = {\n",
    "                    'epoch': epoch,\n",
    "                    'score' : best_loss\n",
    "                }\n",
    "      torch.save(model.state_dict(),   '/nfs/hpc/share/sumons/model_linear_50_sigmoid.pt')\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {running_loss / len(train_loader)}, Validation Loss: {val_loss}')\n",
    "\n",
    "# Validation function\n",
    "def validate_model(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for i, (inputs, labels) in enumerate(dataloader):\n",
    "        inputs = inputs.view(inputs.size(0), -1).to(device)/255.0\n",
    "        mask = torch.rand(inputs.size()) > 0.5\n",
    "        inputs = inputs * mask.to(device)\n",
    "        labels = labels.view(labels.size(0), -1).to(device)/255.0\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs[mask], labels[mask])\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf164b3",
   "metadata": {},
   "source": [
    "## Training the model and then saving the loss in a numpy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c18be2be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_model(model,criterion, optimizer)\n",
    "np.save('/nfs/hpc/share/sumons/loss_dnn.npy', loss_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36d93c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for testing the model on test data\n",
    "# Also gives us reconstructed images\n",
    "def test_model(model, dataloader, criterion):\n",
    "  masked_input = []\n",
    "  reconstructed_image = []\n",
    "  original_image = []\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "      \n",
    "      inputs = inputs.view(inputs.size(0), -1).to(device)/255.0\n",
    "      mask = torch.rand(inputs.size()) > 0.5\n",
    "      inputs = inputs * mask.to(device)\n",
    "      masked_input.append(inputs)\n",
    "      labels = labels.view(labels.size(0), -1).to(device)/255.0\n",
    "      outputs = model(inputs)\n",
    "      reconstructed_image.append(outputs)\n",
    "      original_image.append(labels)\n",
    "      # mask = (inputs != 0)\n",
    "      loss = criterion(outputs[mask], labels[mask])\n",
    "      running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(dataloader), masked_input, reconstructed_image, original_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a45d0a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, masked_input, reconstructed_image, original_image = test_model(model, test_loader, criterion)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d784eb19",
   "metadata": {},
   "source": [
    "## Functions for plotting the reconstruted images from latent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "250888a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_reconstructed_image(index_1, index_2):\n",
    "  image = reconstructed_image[index_1][index_2].cpu()\n",
    "  image = image.view(28, 28)\n",
    "  return image * 255\n",
    "\n",
    "def plot_original_image(index_1, index_2):\n",
    "  image = original_image[index_1][index_2].cpu()\n",
    "  image = image.view(28, 28)\n",
    "  return image * 255\n",
    "\n",
    "def plot_masked_image(index_1, index_2):\n",
    "  image = masked_input[index_1][index_2].cpu()\n",
    "  image = image.view(28, 28)\n",
    "  return image * 255\n",
    "\n",
    "def plot_images(index_1, index_2, save = False):\n",
    "\n",
    "  # Assume that img1, img2, and img3 are your images\n",
    "  img1 = plot_original_image(index_1, index_2)\n",
    "  img2 = plot_masked_image(index_1, index_2)\n",
    "  img3 = plot_reconstructed_image(index_1, index_2)\n",
    "\n",
    "  # Create figure and axes\n",
    "  fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "  # Display an image at each subplot with a title\n",
    "  axs[0].imshow(img1)\n",
    "  axs[0].set_title('Original Image')\n",
    "\n",
    "  axs[1].imshow(img2)\n",
    "  axs[1].set_title('Masked Image')\n",
    "\n",
    "  axs[2].imshow(img3)\n",
    "  axs[2].set_title('Reconstructed Image')\n",
    "\n",
    "  # Remove axes for a better visual output\n",
    "  for ax in axs:\n",
    "      ax.axis('off')\n",
    "  \n",
    "  if save:\n",
    "    plt.savefig('/nfs/hpc/share/sumons/linear_20_0.png')\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "plot_images(0,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb4677",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a392353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn, optim\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c8895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedMNISTDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image, _ = self.data[idx]\n",
    "        image = np.array(image)\n",
    "        image = torch.from_numpy(image).float()\n",
    "\n",
    "        return image, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f516a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root = './data', train = True, download = True)\n",
    "test_data = datasets.MNIST(root = './data', train = False, download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f0b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MaskedMNISTDataset\n",
    "train_dataset = MaskedMNISTDataset(train_data)\n",
    "test_dataset = MaskedMNISTDataset(test_data)\n",
    "\n",
    "# Split the train dataset into training and validation\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2dbb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=3, padding=1)  \n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(16*7*7, 120)  \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 28*28)  \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        # print(x.size())\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1) \n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out.view(-1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1889a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate the model, loss function and optimizer\n",
    "model = CNNModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "loss_array = []\n",
    "\n",
    "# Training Loop\n",
    "def train_model(model, criterion, optimizer, num_epochs=500):\n",
    "  \n",
    "  best_loss = 1000\n",
    "  for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "      \n",
    "      inputs = inputs.to(device)/255.0\n",
    "      mask = torch.rand(inputs.size()) > 0.5\n",
    "      inputs = inputs * mask.to(device)\n",
    "      labels = labels.to(device)/255.0\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs[mask], labels[mask])\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item()\n",
    "\n",
    "    val_loss = validate_model(model, val_loader, criterion)\n",
    "    loss_array.append(val_loss)\n",
    "    if val_loss < best_loss:\n",
    "      best_loss = val_loss\n",
    "      last_checkpoint_info = {\n",
    "                    'epoch': epoch,\n",
    "                    'score' : best_loss\n",
    "                }\n",
    "      torch.save(model.state_dict(),   '/nfs/hpc/share/sumons/model_CNN_50.pt')\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {running_loss / len(train_loader)}, Validation Loss: {val_loss}')\n",
    "\n",
    "# Validation function\n",
    "def validate_model(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for i, (inputs, labels) in enumerate(dataloader):\n",
    "        inputs = inputs.to(device)/255.0\n",
    "        mask = torch.rand(inputs.size()) > 0.5\n",
    "        inputs = inputs * mask.to(device)\n",
    "        labels = labels.to(device)/255.0\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs[mask], labels[mask])\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc1437f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model,criterion, optimizer)\n",
    "np.save('/nfs/hpc/share/sumons/loss_cnn.npy', loss_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb0210bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_array = np.load('/nfs/hpc/share/sumons/loss_cnn.npy')\n",
    "print(loss_array)\n",
    "plt.plot(loss_array)\n",
    "plt.title('Loss vs Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2778d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloader, criterion):\n",
    "  masked_input = []\n",
    "  reconstructed_image = []\n",
    "  original_image = []\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "      \n",
    "      inputs = inputs/255.0\n",
    "      inputs = inputs.to(device)\n",
    "      mask = torch.rand(inputs.size()) > 0.5\n",
    "      inputs = inputs * mask.to(device)\n",
    "      masked_input.append(inputs)\n",
    "      labels = labels/255.0\n",
    "      labels = labels.to(device)\n",
    "      outputs = model(inputs)\n",
    "      reconstructed_image.append(outputs)\n",
    "      original_image.append(labels)\n",
    "      loss = criterion(outputs[mask], labels[mask])\n",
    "      running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(dataloader), masked_input, reconstructed_image, original_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5aa9620",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, masked_input, reconstructed_image, original_image = test_model(model, test_loader, criterion)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac40d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reconstructed_image(index_1, index_2):\n",
    "  image = reconstructed_image[index_1][index_2].cpu()\n",
    "  image = image.view(28, 28)\n",
    "  return image * 255\n",
    "\n",
    "def plot_original_image(index_1, index_2):\n",
    "  image = original_image[index_1][index_2].cpu()\n",
    "  image = image.view(28, 28)\n",
    "  return image * 255\n",
    "\n",
    "def plot_masked_image(index_1, index_2):\n",
    "  image = masked_input[index_1][index_2].cpu()\n",
    "  image = image.view(28, 28)\n",
    "  return image * 255\n",
    "\n",
    "def plot_images(index_1, index_2, save = False):\n",
    "\n",
    "  # Assume that img1, img2, and img3 are your images\n",
    "  img1 = plot_original_image(index_1, index_2)\n",
    "  img2 = plot_masked_image(index_1, index_2)\n",
    "  img3 = plot_reconstructed_image(index_1, index_2)\n",
    "\n",
    "  # Create figure and axes\n",
    "  fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "  # Display an image at each subplot with a title\n",
    "  axs[0].imshow(img1)\n",
    "  axs[0].set_title('Original Image')\n",
    "\n",
    "  axs[1].imshow(img2)\n",
    "  axs[1].set_title('Masked Image')\n",
    "\n",
    "  axs[2].imshow(img3)\n",
    "  axs[2].set_title('Reconstructed Image')\n",
    "\n",
    "  # Remove axes for a better visual output\n",
    "  for ax in axs:\n",
    "      ax.axis('off')\n",
    "  \n",
    "  if save:\n",
    "    plt.savefig('/nfs/hpc/share/sumons/CNN_50%_4.png')\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "plot_images(0,6, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ec7b8c",
   "metadata": {},
   "source": [
    "# Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f866125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn, optim\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b99853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedMNISTDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image, _ = self.data[idx]\n",
    "        image = np.array(image)\n",
    "        image = torch.from_numpy(image).float()\n",
    "\n",
    "        return image, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed84243",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root = './data', train = True, download = True)\n",
    "test_data = datasets.MNIST(root = './data', train = False, download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77c574e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MaskedMNISTDataset\n",
    "train_dataset = MaskedMNISTDataset(train_data)\n",
    "test_dataset = MaskedMNISTDataset(test_data)\n",
    "\n",
    "# Split the train dataset into training and validation\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b97da9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1)\n",
    "        self.fc1 = nn.Linear(in_features=128*7*7, out_features=1024)\n",
    "        self.fc21 = nn.Linear(in_features=1024, out_features=20)  # mu layer\n",
    "        self.fc22 = nn.Linear(in_features=1024, out_features=20)  # logvar layer\n",
    "\n",
    "        # Decoder\n",
    "        self.fc3 = nn.Linear(in_features=20, out_features=1024)\n",
    "        self.fc4 = nn.Linear(in_features=1024, out_features=128*7*7)\n",
    "        self.convT1 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
    "        self.convT2 = nn.ConvTranspose2d(in_channels=64, out_channels=1, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.conv1(x))\n",
    "        h2 = F.relu(self.conv2(h1))\n",
    "        h2 = h2.view(h2.size(0), -1)\n",
    "        h3 = F.relu(self.fc1(h2))\n",
    "        return self.fc21(h3), self.fc22(h3)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h4 = F.relu(self.fc3(z))\n",
    "        h5 = F.relu(self.fc4(h4))\n",
    "        h5 = h5.view(h5.size(0), 128, 7, 7)\n",
    "        h6 = F.relu(self.convT1(h5))\n",
    "        return torch.sigmoid(self.convT2(h6))  # pixel values are in [0,1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        # print(z.size())\n",
    "        z = self.decode(z)\n",
    "        # print(z.size())\n",
    "        z = z.squeeze(1)\n",
    "        # print(z.size())\n",
    "        return z, mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2456c835",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the loss function for VAE\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    MSE = criterion(recon_x, x)\n",
    "#     MSE = criterion(recon_x.view(-1, 784), x.view(-1, 784))\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return MSE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51e0314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "loss_array = []\n",
    "def train_model(model, optimizer, num_epochs=500):\n",
    "  \n",
    "  best_loss = 1000\n",
    "  for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "      \n",
    "      inputs = inputs.to(device)/255.0\n",
    "      mask = torch.rand(inputs.size()) > 0.8\n",
    "      inputs = inputs * mask.to(device)\n",
    "      labels = labels.to(device)/255.0\n",
    "      outputs, mu, logvar = model(inputs)\n",
    "      # print(f\"in the training loop. Outputs size: {outputs.size()}, Masks size: {outputs[mask].size()}, Original Mask size: {mask.size()}\")\n",
    "      loss = loss_function(outputs[mask].to(device), labels[mask].to(device), mu, logvar)\n",
    "      # outputs = model(inputs)\n",
    "      # loss = criterion(outputs[mask], labels[mask])\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item()\n",
    "\n",
    "    val_loss = validate_model(model, val_loader)\n",
    "    loss_array.append(val_loss)\n",
    "    if val_loss < best_loss:\n",
    "      best_loss = val_loss\n",
    "      last_checkpoint_info = {\n",
    "                    'epoch': epoch,\n",
    "                    'score' : best_loss\n",
    "                }\n",
    "      torch.save(model.state_dict(),   '/nfs/hpc/share/sumons/model_vae_20.pt')\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {running_loss / len(train_loader)}, Validation Loss: {val_loss}')\n",
    "\n",
    "# Validation function\n",
    "def validate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for i, (inputs, labels) in enumerate(dataloader):\n",
    "        inputs = inputs.to(device)/255.0\n",
    "        mask = torch.rand(inputs.size()) > 0.8\n",
    "        inputs = inputs * mask.to(device)\n",
    "        labels = labels.to(device)/255.0\n",
    "        outputs, mu, logvar = model(inputs)\n",
    "        loss = loss_function(outputs[mask].to(device), labels[mask].to(device), mu, logvar)\n",
    "        # loss = criterion(outputs[mask], labels[mask])\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(dataloader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddc7bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model,optimizer)\n",
    "np.save('/nfs/hpc/share/sumons/loss_vae.npy', loss_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "556d6500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloader):\n",
    "  masked_input = []\n",
    "  reconstructed_image = []\n",
    "  original_image = []\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "      \n",
    "      inputs = inputs/255.0\n",
    "      inputs = inputs.to(device)\n",
    "      mask = torch.rand(inputs.size()) > 0.6\n",
    "      inputs = inputs * mask.to(device)\n",
    "      masked_input.append(inputs)\n",
    "      labels = labels/255.0\n",
    "      labels = labels.to(device)\n",
    "      outputs, mu, logvar = model(inputs)\n",
    "      reconstructed_image.append(outputs)\n",
    "      original_image.append(labels)\n",
    "      loss = loss_function(outputs*mask.to(device), labels*mask.to(device), mu, logvar)\n",
    "      # loss = criterion(outputs[mask], labels[mask])\n",
    "      running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(dataloader), masked_input, reconstructed_image, original_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "802fdb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, masked_input, reconstructed_image, original_image = test_model(model, test_loader)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0c46cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reconstructed_image(index_1, index_2):\n",
    "  image = reconstructed_image[index_1][index_2].cpu()\n",
    "  image = image.view(28, 28)\n",
    "  return image * 255\n",
    "\n",
    "def plot_original_image(index_1, index_2):\n",
    "  image = original_image[index_1][index_2].cpu()\n",
    "  image = image.view(28, 28)\n",
    "  return image * 255\n",
    "\n",
    "def plot_masked_image(index_1, index_2):\n",
    "  image = masked_input[index_1][index_2].cpu()\n",
    "  image = image.view(28, 28)\n",
    "  return image * 255\n",
    "\n",
    "def plot_images(index_1, index_2, save = False):\n",
    "\n",
    "  # Assume that img1, img2, and img3 are your images\n",
    "  img1 = plot_original_image(index_1, index_2)\n",
    "  img2 = plot_masked_image(index_1, index_2)\n",
    "  img3 = plot_reconstructed_image(index_1, index_2)\n",
    "\n",
    "  # Create figure and axes\n",
    "  fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "  # Display an image at each subplot with a title\n",
    "  axs[0].imshow(img1)\n",
    "  axs[0].set_title('Original Image')\n",
    "\n",
    "  axs[1].imshow(img2)\n",
    "  axs[1].set_title('Masked Image')\n",
    "\n",
    "  axs[2].imshow(img3)\n",
    "  axs[2].set_title('Reconstructed Image')\n",
    "\n",
    "  # Remove axes for a better visual output\n",
    "  for ax in axs:\n",
    "      ax.axis('off')\n",
    "  \n",
    "  if save:\n",
    "    plt.savefig('/nfs/hpc/share/sumons/vae_20%transfer_60_2.png')\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "plot_images(0,35, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c67a2a",
   "metadata": {},
   "source": [
    "# Graphs for the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd10c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the loss files \n",
    "\n",
    "dnn = np.load('/nfs/hpc/share/sumons/loss_dnn.npy')\n",
    "cnn = np.load('/nfs/hpc/share/sumons/loss_cnn.npy')\n",
    "vae = np.load('/nfs/hpc/share/sumons/vae_los_mses.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5770ef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming dnn, cnn, and vae are your data\n",
    "epochs = range(1, len(dnn) + 1)\n",
    "\n",
    "# Plot DNN loss\n",
    "plt.plot(epochs[:300], dnn[:300], 'b-.', marker='o', markersize=1, label='DNN')\n",
    "\n",
    "# Plot CNN loss\n",
    "plt.plot(epochs[:300], cnn[:300], 'r-.', marker='v', markersize=1, label='CNN')\n",
    "\n",
    "# Plot VAE loss\n",
    "plt.plot(epochs[:300], vae[:300], 'g-.', marker='s', markersize=1, label='VAE')\n",
    "\n",
    "# Setting title and labels\n",
    "plt.title('Loss vs Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Setting y-axis limits\n",
    "# plt.ylim(0.015, 0.225)\n",
    "\n",
    "# Setting grid and ticks on y-axis\n",
    "# plt.yticks(np.linspace(0.015, 0.225, 11))\n",
    "# \n",
    "# Adding grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Adding legend\n",
    "plt.legend()\n",
    "\n",
    "# Display plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
